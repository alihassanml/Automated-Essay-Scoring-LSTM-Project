{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":71485,"databundleVersionId":8059942,"sourceType":"competition"},{"sourceId":9244248,"sourceType":"datasetVersion","datasetId":5592105}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Automated Essay Scoring System**\n*  Description\n The Automated Essay Scoring System leverages advanced natural language processing (NLP) techniques to evaluate and grade essays based on various criteria, including content, coherence, grammar, and more. Using deep learning models, specifically Long Short-Term Memory (LSTM) networks, this system aims to provide accurate and consistent essay scores, mimicking human grading.","metadata":{}},{"cell_type":"markdown","source":"# **Tools**\n* TensorFlow: Framework for building and training the LSTM model.\n* Keras: High-level API for TensorFlow to facilitate model creation.\n* PyTorch: Optional for any additional modeling or experimentation.\n* NLTK: Library for text processing and feature extraction.\n* SpaCy: Library for advanced NLP tasks, including tokenization and lemmatization.\n# **Features**\n* Automated Scoring: Grades essays based on multiple criteria.\n* Content Analysis: Evaluates the relevance and richness of content.\n* Coherence Assessment: Measures the logical flow and structure of the essay.\n* Grammar Checking: Identifies and scores grammatical accuracy.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nimport nltk\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.corpus import stopwords\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.layers import Dense,Dropout,LSTM,GRU,Embedding\nfrom keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.models import Sequential\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:45:58.929113Z","iopub.execute_input":"2024-08-25T14:45:58.929742Z","iopub.status.idle":"2024-08-25T14:46:20.312657Z","shell.execute_reply.started":"2024-08-25T14:45:58.929701Z","shell.execute_reply":"2024-08-25T14:46:20.311653Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"plt.style.use('ggplot')\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Preparation**\n* Collect and preprocess your essay dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/autoscoredetect/Processed_data.csv')\ndf.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = df[['essay','final_score']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.title('Number of essay getting Star')\ndata['final_score'].value_counts().plot(kind='bar')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# USE NLP TO MAKE TO REMOVE UNRECOMENDED TEXT","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:47:38.794742Z","iopub.execute_input":"2024-08-25T14:47:38.795697Z","iopub.status.idle":"2024-08-25T14:47:38.799565Z","shell.execute_reply.started":"2024-08-25T14:47:38.795652Z","shell.execute_reply":"2024-08-25T14:47:38.798567Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import re\nstopwords_set = set(stopwords.words('english'))\nemoji = re.compile('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)')\n\ndef Clean_text(text):\n    cleanText = re.sub('http\\S+\\s', ' ', text)\n    cleanText = re.sub('RT|cc', ' ', cleanText)\n    cleanText = re.sub('#\\S+\\s', ' ', cleanText)\n    cleanText = re.sub('@\\S+', '  ', cleanText)  \n    cleanText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', cleanText)\n    cleanText = re.sub(r'[^\\x00-\\x7f]', ' ', cleanText) \n    cleanText = re.sub('\\s+', ' ', cleanText)\n    return cleanText\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = data['essay'].apply(lambda x:Clean_text(x))\ny = data['final_score']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data PreprocessingÂ¶**\n* Text Cleaning: Remove special characters, punctuation, and numbers. Tokenization: Convert text into a sequence of tokens (words). Padding: Ensure all sequences have the same length by padding shorter sequences. ","metadata":{}},{"cell_type":"code","source":"tokenizer = Tokenizer()\ntokenizer.fit_on_texts(X)\nsequences = tokenizer.texts_to_sequences(X)\nmax_len = max(len(x) for x in sequences)\nprint(max_len)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_size = len(tokenizer.word_index) +1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sequences_data = pad_sequences(sequences,maxlen=max_len,padding='pre')\nsequences_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scalar = MinMaxScaler(feature_range=(0, 10))\nreshaped = data['final_score'].values.reshape(-1, 1)\ny = scalar.fit_transform(reshaped).flatten()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train ","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:49:19.605643Z","iopub.execute_input":"2024-08-25T14:49:19.606446Z","iopub.status.idle":"2024-08-25T14:49:19.610376Z","shell.execute_reply.started":"2024-08-25T14:49:19.606406Z","shell.execute_reply":"2024-08-25T14:49:19.609437Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(sequences_data, y, test_size=0.33, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=max_len))\nmodel.add(LSTM(128, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(64))\nmodel.add(Dense(11,activation='softmax')) \nmodel.build((None, max_len))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n    metrics=['Accuracy']\n)\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X_train,y_train,epochs=20,validation_split=0.3,validation_data=(X_test,y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(model.history.history['Accuracy'])\nplt.plot(model.history.history['val_Accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train','test'],loc='upper left')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(model.history.history['loss'])\nplt.plot(model.history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train','test'],loc='upper left')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss,accuracy = model.evaluate(X_test,y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted = np.array(y_pred)\npredicted","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(text):\n    tokenize = tokenizer.texts_to_sequences([text])[0]\n    token_list = pad_sequences([tokenize],maxlen=max_len-1,padding='pre')\n    predicted = model.predict(token_list,verbose=0)\n    predicted = np.argmax(np.array(predicted),axis=1)\n    print(predicted )\n    return predicted ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = data['essay'][2]\npredict(text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\nwith open('tokenizer.pkl', 'wb') as file:\n    pickle.dump(tokenizer, file)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('model.h5')","metadata":{},"execution_count":null,"outputs":[]}]}